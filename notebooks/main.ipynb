{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison in The Domain of Brain Tumor Image Classification\n",
    "For our final project for Spring 2025, CS 4644 - Deep Learning, we analyze and compare the results from three unique models:\n",
    "1. 3D CNN - Turning 2D images into 3D datapoints to reconstruct a full brain image.\n",
    "2. ResNet18 - Applying transfer learning by taking a pretrained ResNet-18 model (trained on ImageNet) and adapting it to MRI scans through the fine-tuning of a final fully connected layer.\n",
    "3. Inception - Applying transfer learning in the same way as ResNet, but for another popular and successful model.\n",
    "\n",
    "The following code allows the reader to experiment with these 3 models and observe their results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0: Get necessary imports and set global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/TumorTrace/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/usr/local/Caskroom/miniconda/base/envs/TumorTrace/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <E03EDA44-89AE-3115-9796-62BA9E0E2EDE> /usr/local/Caskroom/miniconda/base/envs/TumorTrace/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in:     <ADD14A6E-669F-3F53-A802-D8FBD6AA3F40> /usr/local/Caskroom/miniconda/base/envs/TumorTrace/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/usr/local/Caskroom/miniconda/base/envs/TumorTrace/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/Caskroom/miniconda/base/envs/TumorTrace/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/Caskroom/miniconda/base/envs/TumorTrace/lib/python3.11/site-packages/numpy/core/_methods.py:206: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/usr/local/Caskroom/miniconda/base/envs/TumorTrace/lib/python3.11/site-packages/numpy/core/_methods.py:163: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/usr/local/Caskroom/miniconda/base/envs/TumorTrace/lib/python3.11/site-packages/numpy/core/_methods.py:198: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "# Basic imports\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Model imports\n",
    "from src.models import (\n",
    "    CNN_3D,\n",
    "    MyResNet,\n",
    "    MyInception\n",
    ")\n",
    "print('1')\n",
    "# Helper imports\n",
    "from utils.utils import (\n",
    "    compute_mean_and_std,\n",
    "    save_trained_model_weights,\n",
    "    convert_pickle_to_folder\n",
    ")\n",
    "print('2')\n",
    "from src import (\n",
    "    Trainer,\n",
    "    get_optimizer\n",
    ")\n",
    "print('3')\n",
    "from data.data_transforms import (\n",
    "    get_fundamental_transforms,\n",
    "    get_fundamental_normalization_transforms,\n",
    "    get_fundamental_augmentation_transforms,\n",
    "    get_all_transforms,\n",
    ")\n",
    "print('4')\n",
    "from utils.confusion_matrix import (\n",
    "    generate_confusion_data,\n",
    "    generate_confusion_matrix,\n",
    "    plot_confusion_matrix,\n",
    "    get_pred_images_for_target,\n",
    "    generate_and_plot_confusion_matrix,\n",
    "    generate_and_plot_accuracy_table,\n",
    ")\n",
    "\n",
    "# Global variables\n",
    "data_path = \"data/processed_mri\"\n",
    "model_path = \"src/models\"\n",
    "\n",
    "dataset_mean, dataset_std = compute_mean_and_std(data_path)\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Skipping conversion. Folder '../data/processed_mri' already exists.\n"
     ]
    }
   ],
   "source": [
    "convert_pickle_to_folder(\n",
    "    pickle_path=\"../data/archive/brain_tumor_mri/new_dataset/training_data.pickle\",\n",
    "    output_dir=\"../data/processed_mri\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/TumorTrace/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/Caskroom/miniconda/base/envs/TumorTrace/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyResNet(\n",
      "  (conv_layers): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  )\n",
      "  (fc_layers): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=512, out_features=3, bias=True)\n",
      "  )\n",
      "  (loss_criterion): CrossEntropyLoss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_resnet = MyResNet(num_classes=num_classes)\n",
    "print(model_resnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Test 3D Convolutional Nerual Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_size = (224,224) # Double check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn = CNN_3D(num_classes=num_classes)\n",
    "\n",
    "cnn_optimizer_config = {\"optimizer_type\": \"adam\", \"lr\": 1e-3, \"weight_decay\": 1e-8} # Tune these\n",
    "cnn_optimizer = get_optimizer(model_cnn, cnn_optimizer_config)\n",
    "\n",
    "cnn_trainer = Trainer(\n",
    "    data_dir=data_path,\n",
    "    model=model_cnn,\n",
    "    optimizer=cnn_optimizer,\n",
    "    model_dir=os.path.join(model_path, \"CNN_3D\"),\n",
    "    train_data_transforms=get_all_transforms(inp_size, [dataset_mean], [dataset_std]),\n",
    "    val_data_transforms=get_fundamental_normalization_transforms(\n",
    "        inp_size, [dataset_mean], [dataset_std]\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    load_from_disk=False,\n",
    "    cuda=torch.cuda.is_available(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cnn_trainer.run_training_loop(num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_trainer.plot_loss_history()\n",
    "cnn_trainer.plot_accuracy()\n",
    "\n",
    "cnn_train_accuracy = cnn_trainer.train_accuracy_history[-1]\n",
    "cnn_validation_accuracy = cnn_trainer.validation_accuracy_history[-1]\n",
    "print(\n",
    "    \"Train Accuracy = {}; Validation Accuracy = {}\".format(\n",
    "        cnn_train_accuracy, cnn_validation_accuracy\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_trained_model_weights(model_cnn, out_dir=os.path.join(model_path, \"CNN_3D\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Test ResNet Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_size = (224,224) # Double check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet = MyResNet(num_classes=num_classes)\n",
    "\n",
    "resnet_optimizer_config = {\"optimizer_type\": \"adam\", \"lr\": 1e-3, \"weight_decay\": 1e-8} # Tune these\n",
    "resnet_optimizer = get_optimizer(model_resnet, resnet_optimizer_config)\n",
    "\n",
    "resnet_trainer = Trainer(\n",
    "    data_dir=data_path,\n",
    "    model=model_resnet,\n",
    "    optimizer=resnet_optimizer,\n",
    "    model_dir=os.path.join(model_path, \"ResNet\"),\n",
    "    train_data_transforms=get_all_transforms(inp_size, [dataset_mean], [dataset_std]),\n",
    "    val_data_transforms=get_fundamental_normalization_transforms(\n",
    "        inp_size, [dataset_mean], [dataset_std]\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    load_from_disk=False,\n",
    "    cuda=torch.cuda.is_available(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "resnet_trainer.run_training_loop(num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_trained_model_weights(model_resnet, out_dir=os.path.join(model_path, \"ResNet\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Test Inception Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_size = (299,299) # Double check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inception = MyInception(num_classes=num_classes)\n",
    "\n",
    "inception_optimizer_config = {\"optimizer_type\": \"adam\", \"lr\": 1e-3, \"weight_decay\": 1e-8} # Tune these\n",
    "inception_optimizer = get_optimizer(model_inception, inception_optimizer_config)\n",
    "\n",
    "inception_trainer = Trainer(\n",
    "    data_dir=data_path,\n",
    "    model=model_inception,\n",
    "    optimizer=inception_optimizer,\n",
    "    model_dir=os.path.join(model_path, \"Inception\"),\n",
    "    train_data_transforms=get_all_transforms(inp_size, [dataset_mean], [dataset_std]),\n",
    "    val_data_transforms=get_fundamental_normalization_transforms(\n",
    "        inp_size, [dataset_mean], [dataset_std]\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    load_from_disk=False,\n",
    "    cuda=torch.cuda.is_available(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "inception_trainer.run_training_loop(num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_trained_model_weights(model_inception, out_dir=os.path.join(model_path, \"Inception\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Analyze Graphs and Final Accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss & Accuracy Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_trainer.plot_loss_history()\n",
    "cnn_trainer.plot_accuracy()\n",
    "\n",
    "cnn_train_accuracy = cnn_trainer.train_accuracy_history[-1]\n",
    "cnn_validation_accuracy = cnn_trainer.validation_accuracy_history[-1]\n",
    "print(\n",
    "    \"Train Accuracy = {}; Validation Accuracy = {}\".format(\n",
    "        cnn_train_accuracy, cnn_validation_accuracy\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_trainer.plot_loss_history()\n",
    "resnet_trainer.plot_accuracy()\n",
    "\n",
    "resnet_train_accuracy = resnet_trainer.train_accuracy_history[-1]\n",
    "resnet_validation_accuracy = resnet_trainer.validation_accuracy_history[-1]\n",
    "print(\n",
    "    \"Train Accuracy = {}; Validation Accuracy = {}\".format(\n",
    "        resnet_train_accuracy, resnet_validation_accuracy\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_trainer.plot_loss_history()\n",
    "inception_trainer.plot_accuracy()\n",
    "\n",
    "inception_train_accuracy = inception_trainer.train_accuracy_history[-1]\n",
    "inception_validation_accuracy = inception_trainer.validation_accuracy_history[-1]\n",
    "print(\n",
    "    \"Train Accuracy = {}; Validation Accuracy = {}\".format(\n",
    "        inception_train_accuracy, inception_validation_accuracy\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_and_plot_confusion_matrix(model_cnn, cnn_trainer.val_dataset, use_cuda=torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_and_plot_confusion_matrix(model_resnet, resnet_trainer.val_dataset, use_cuda=torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_and_plot_confusion_matrix(model_inception, inception_trainer.val_dataset, use_cuda=torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze errors that occurred from confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = resnet_trainer # Change this\n",
    "model = model_resnet # Change this\n",
    "\n",
    "# Analyze confusion matrix and change these to observe results\n",
    "predicted_class_num = 0\n",
    "true_class_num = 0\n",
    "\n",
    "correct_class = [k for k, v in trainer.val_dataset.class_dict.items() if v == true_class_num][0]\n",
    "pred_class = key = [k for k, v in trainer.val_dataset.class_dict.items() if v == predicted_class_num][0]\n",
    "print(trainer.val_dataset.class_dict)\n",
    "\n",
    "paths = get_pred_images_for_target(model, trainer.val_dataset, predicted_class_num, true_class_num, torch.cuda.is_available())\n",
    "max_count = 10\n",
    "count = 0\n",
    "for path in paths:\n",
    "    img = Image.open(path).convert(mode='L')\n",
    "    if (count != max_count):\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.title(f'Image of {correct_class}, misclassified as {pred_class}')\n",
    "        plt.axis('off')  # Removes axis ticks\n",
    "        plt.show()\n",
    "        count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TumorTrace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
