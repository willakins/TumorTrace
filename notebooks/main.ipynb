{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the notebook dedicated to running our models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gather the dataset and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/TumorTrace/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/usr/local/Caskroom/miniconda/base/envs/TumorTrace/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <E03EDA44-89AE-3115-9796-62BA9E0E2EDE> /usr/local/Caskroom/miniconda/base/envs/TumorTrace/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in:     <ADD14A6E-669F-3F53-A802-D8FBD6AA3F40> /usr/local/Caskroom/miniconda/base/envs/TumorTrace/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: torch.Size([16, 1, 512, 512, 3])\n",
      "Label: tensor([3., 1., 1., 2., 3., 2., 3., 2., 2., 3., 2., 3., 2., 2., 3., 1.])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from data.data_preprocessing import MRIDataset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import pickle\n",
    "\n",
    "# Applying random transformations to vary data\n",
    "transformations = transforms.Compose([\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip()\n",
    "])\n",
    "\n",
    "# Data preloaded from pickle file\n",
    "data_path = os.path.abspath(os.path.join(\"..\", \"data\", \"archive\", \"brain_tumor_mri\", \"new_dataset\", \"training_data.pickle\"))\n",
    "with open(data_path, 'rb') as file:\n",
    "    loaded_data = pickle.load(file)\n",
    "\n",
    "# Unpacking the data into the images and their corresponding labels\n",
    "images, labels = zip(*loaded_data)\n",
    "dataset = MRIDataset(images, labels, transformations, model_type=None)\n",
    "\n",
    "# Splitting the dataset into training and testing\n",
    "training_size = int(.8 * len(dataset))\n",
    "testing_size = len(dataset) - training_size\n",
    "training_dataset, testing_dataset = random_split(dataset, [training_size, testing_size])\n",
    "\n",
    "# Two separate loaders for training and testing\n",
    "train_loader = DataLoader(training_dataset, batch_size=16, shuffle=True)\n",
    "testing_loader = DataLoader(testing_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Debug comment out later\n",
    "for sample_image, sample_label in train_loader:\n",
    "    print(f\"Image shape: {sample_image.shape}\")\n",
    "    print(f\"Label: {sample_label}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the 3D CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch number 0, Loss: 1.0783663988113403\n",
      "Batch number 1, Loss: 445.1538391113281\n",
      "Batch number 2, Loss: 798.89306640625\n",
      "Batch number 3, Loss: 123.47567749023438\n",
      "Batch number 4, Loss: 36.87293243408203\n",
      "Batch number 5, Loss: 27.177471160888672\n",
      "Batch number 6, Loss: 39.0335807800293\n",
      "Batch number 7, Loss: 14.636894226074219\n",
      "Batch number 8, Loss: 9.445398330688477\n",
      "Batch number 9, Loss: 18.422515869140625\n",
      "Batch number 10, Loss: 7.320761680603027\n",
      "Batch number 11, Loss: 5.22018575668335\n",
      "Batch number 12, Loss: 1.8114267587661743\n",
      "Batch number 13, Loss: 1.2464625835418701\n",
      "Batch number 14, Loss: 1.4600677490234375\n"
     ]
    }
   ],
   "source": [
    "from models.CNN_3D.model import CNN_3D\n",
    "from models.CNN_3D.train import Trainer\n",
    "\n",
    "# Set up the model, criterion, and optimizer\n",
    "model = CNN_3D(num_classes=3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Initialize the Trainer class\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=testing_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=10,\n",
    "    device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the ResNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.ResNet.model import ResNet\n",
    "from models.ResNet.train import train\n",
    "\n",
    "model = ResNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the Inception model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.Inception.model import Inception\n",
    "from models.Inception.train import train\n",
    "\n",
    "model = Inception()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.visualizer.plot_loss()\n",
    "trainer.visualizer.plot_accuracy()\n",
    "# Add ability to visualize confusion matrix probably"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TumorTrace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
