{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the notebook dedicated to running our models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gather the dataset and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: torch.Size([16, 1, 512, 512, 3])\n",
      "Label: tensor([2., 2., 1., 2., 1., 3., 1., 3., 2., 3., 2., 3., 3., 3., 1., 3.])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from data.data_preprocessing import MRIDataset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import pickle\n",
    "\n",
    "# Applying random transformations to vary data\n",
    "transformations = transforms.Compose([\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip()\n",
    "])\n",
    "\n",
    "# Data preloaded from pickle file\n",
    "data_path = os.path.abspath(os.path.join(\"..\", \"data\", \"archive\", \"brain_tumor_mri\", \"new_dataset\", \"training_data.pickle\"))\n",
    "with open(data_path, 'rb') as file:\n",
    "    loaded_data = pickle.load(file)\n",
    "\n",
    "# Unpacking the data into the images and their corresponding labels\n",
    "images, labels = zip(*loaded_data)\n",
    "dataset = MRIDataset(images, labels, transformations, model_type=None)\n",
    "\n",
    "# Splitting the dataset into training and testing\n",
    "training_size = int(.8 * len(dataset))\n",
    "testing_size = len(dataset) - training_size\n",
    "training_dataset, testing_dataset = random_split(dataset, [training_size, testing_size])\n",
    "\n",
    "# Two separate loaders for training and testing\n",
    "train_loader = DataLoader(training_dataset, batch_size=16, shuffle=True)\n",
    "testing_loader = DataLoader(testing_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Debug comment out later\n",
    "for sample_image, sample_label in train_loader:\n",
    "    print(f\"Image shape: {sample_image.shape}\")\n",
    "    print(f\"Label: {sample_label}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the 3D CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch number 0, Loss: 1.0399820804595947\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from models.CNN_3D.model import CNN_3D\n",
    "from models.CNN_3D.train import Trainer\n",
    "\n",
    "# Set up the model, criterion, and optimizer\n",
    "model = CNN_3D(num_classes=3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Initialize the Trainer class\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=testing_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=10,\n",
    "    device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the ResNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.ResNet.model import ResNet\n",
    "from models.ResNet.train import train\n",
    "\n",
    "model = ResNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the Inception model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.Inception.model import Inception\n",
    "from models.Inception.train import train\n",
    "\n",
    "model = Inception()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "trainer.visualizer.plot_loss()\n",
    "trainer.visualizer.plot_accuracy()\n",
    "\n",
    "# Re-evaluate model and retrieve predictions\n",
    "val_accuracy, y_true, y_pred = trainer.evaluate(return_preds=True)\n",
    "\n",
    "# Visualize confusion matrix and classification report\n",
    "trainer.visualizer.evaluation_summary(y_true, y_pred)\n",
    "\n",
    "# Save all plots\n",
    "trainer.visualizer.save_plots(\"results/figures/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
