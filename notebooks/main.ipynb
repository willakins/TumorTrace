{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison in The Domain of Brain Tumor Image Classification\n",
    "For our final project for Spring 2025, CS 4644 - Deep Learning, we analyze and compare the results from three unique models:\n",
    "1. 3D CNN - Turning 2D images into 3D datapoints to reconstruct a full brain image.\n",
    "2. ResNet18 - Applying transfer learning by taking a pretrained ResNet-18 model (trained on ImageNet) and adapting it to MRI scans through the fine-tuning of a final fully connected layer.\n",
    "3. Inception - Applying transfer learning in the same way as ResNet, but for another popular and successful model.\n",
    "\n",
    "The following code allows the reader to experiment with these 3 models and observe their results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0: Get necessary imports and set global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/willakins/Downloads/project-folder/Git/TumorTrace/TumorTrace/notebooks\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data.Image_Loader import MRIDataset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import pickle\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "# Model imports\n",
    "from src.models.CNN_3D.model import CNN_3D\n",
    "from src.models.ResNet.model import MyResNet\n",
    "from src.models.Inception.model import MyInception\n",
    "\n",
    "# Helper imports\n",
    "from utils.utils import compute_mean_and_std\n",
    "from utils.utils import save_trained_model_weights\n",
    "from utils.utils import convert_pickle_to_folder\n",
    "from src.runner import Trainer\n",
    "from src.optimizer import get_optimizer\n",
    "from data.data_transforms import (\n",
    "    get_fundamental_transforms,\n",
    "    get_fundamental_normalization_transforms,\n",
    "    get_fundamental_augmentation_transforms,\n",
    "    get_all_transforms,\n",
    ")\n",
    "from utils.confusion_matrix import (\n",
    "    generate_confusion_data,\n",
    "    generate_confusion_matrix,\n",
    "    plot_confusion_matrix,\n",
    "    get_pred_images_for_target,\n",
    "    generate_and_plot_confusion_matrix,\n",
    "    generate_and_plot_accuracy_table,\n",
    ")\n",
    "\n",
    "# Global variables\n",
    "data_path = \"data/processed_mri\"\n",
    "model_path = \"src/models\"\n",
    "\n",
    "dataset_mean, dataset_std = compute_mean_and_std(data_path)\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_pickle_to_folder(\n",
    "    pickle_path=\"../data/archive/brain_tumor_mri/new_dataset/training_data.pickle\",\n",
    "    output_dir=\"../data/processed_mri\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet = MyResNet()\n",
    "print(model_resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Data preloaded from pickle file\n",
    "with open(data_path, 'rb') as file:\n",
    "    loaded_data = pickle.load(file)\n",
    "\n",
    "# Unpacking the data into the images and their corresponding labels\n",
    "images, labels = zip(*loaded_data)\n",
    "dataset = MRIDataset(images, labels, transformations, model_type=None)\n",
    "\n",
    "# Splitting the dataset into training and testing\n",
    "training_size = int(.8 * len(dataset))\n",
    "testing_size = len(dataset) - training_size\n",
    "training_dataset, testing_dataset = random_split(dataset, [training_size, testing_size])\n",
    "\n",
    "# Two separate loaders for training and testing\n",
    "train_loader = DataLoader(training_dataset, batch_size=16, shuffle=True)\n",
    "testing_loader = DataLoader(testing_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Debug comment out later\n",
    "for sample_image, sample_label in train_loader:\n",
    "    print(f\"Image shape: {sample_image.shape}\")\n",
    "    print(f\"Label: {sample_label}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Test 3D Convolutional Nerual Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_size = (224,224) # Double check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn = CNN_3D(num_classes=num_classes)\n",
    "\n",
    "cnn_optimizer_config = {\"optimizer_type\": \"adam\", \"lr\": 1e-3, \"weight_decay\": 1e-8} # Tune these\n",
    "cnn_optimizer = get_optimizer(model_cnn, cnn_optimizer_config)\n",
    "\n",
    "cnn_trainer = Trainer(\n",
    "    data_dir=data_path,\n",
    "    model=model_cnn,\n",
    "    optimizer=cnn_optimizer,\n",
    "    model_dir=os.path.join(model_path, \"CNN_3D\"),\n",
    "    train_data_transforms=get_all_transforms(inp_size, [dataset_mean], [dataset_std]),\n",
    "    val_data_transforms=get_fundamental_normalization_transforms(\n",
    "        inp_size, [dataset_mean], [dataset_std]\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    load_from_disk=False,\n",
    "    cuda=torch.cuda.is_available(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cnn_trainer.run_training_loop(num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_trainer.plot_loss_history()\n",
    "cnn_trainer.plot_accuracy()\n",
    "\n",
    "cnn_train_accuracy = cnn_trainer.train_accuracy_history[-1]\n",
    "cnn_validation_accuracy = cnn_trainer.validation_accuracy_history[-1]\n",
    "print(\n",
    "    \"Train Accuracy = {}; Validation Accuracy = {}\".format(\n",
    "        cnn_train_accuracy, cnn_validation_accuracy\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_trained_model_weights(model_cnn, out_dir=os.path.join(model_path, \"CNN_3D\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Test ResNet Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_size = (224,224) # Double check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet = MyResNet(num_classes=num_classes)\n",
    "\n",
    "resnet_optimizer_config = {\"optimizer_type\": \"adam\", \"lr\": 1e-3, \"weight_decay\": 1e-8} # Tune these\n",
    "resnet_optimizer = get_optimizer(model_resnet, resnet_optimizer_config)\n",
    "\n",
    "resnet_trainer = Trainer(\n",
    "    data_dir=data_path,\n",
    "    model=model_resnet,\n",
    "    optimizer=resnet_optimizer,\n",
    "    model_dir=os.path.join(model_path, \"ResNet\"),\n",
    "    train_data_transforms=get_all_transforms(inp_size, [dataset_mean], [dataset_std]),\n",
    "    val_data_transforms=get_fundamental_normalization_transforms(\n",
    "        inp_size, [dataset_mean], [dataset_std]\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    load_from_disk=False,\n",
    "    cuda=torch.cuda.is_available(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "resnet_trainer.run_training_loop(num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_trained_model_weights(model_resnet, out_dir=os.path.join(model_path, \"ResNet\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Test Inception Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_size = (299,299) # Double check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inception = MyInception(num_classes=num_classes)\n",
    "\n",
    "inception_optimizer_config = {\"optimizer_type\": \"adam\", \"lr\": 1e-3, \"weight_decay\": 1e-8} # Tune these\n",
    "inception_optimizer = get_optimizer(model_inception, inception_optimizer_config)\n",
    "\n",
    "inception_trainer = Trainer(\n",
    "    data_dir=data_path,\n",
    "    model=model_inception,\n",
    "    optimizer=inception_optimizer,\n",
    "    model_dir=os.path.join(model_path, \"Inception\"),\n",
    "    train_data_transforms=get_all_transforms(inp_size, [dataset_mean], [dataset_std]),\n",
    "    val_data_transforms=get_fundamental_normalization_transforms(\n",
    "        inp_size, [dataset_mean], [dataset_std]\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    load_from_disk=False,\n",
    "    cuda=torch.cuda.is_available(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "inception_trainer.run_training_loop(num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_trained_model_weights(model_inception, out_dir=os.path.join(model_path, \"Inception\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Analyze Graphs and Final Accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss & Accuracy Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_trainer.plot_loss_history()\n",
    "cnn_trainer.plot_accuracy()\n",
    "\n",
    "cnn_train_accuracy = cnn_trainer.train_accuracy_history[-1]\n",
    "cnn_validation_accuracy = cnn_trainer.validation_accuracy_history[-1]\n",
    "print(\n",
    "    \"Train Accuracy = {}; Validation Accuracy = {}\".format(\n",
    "        cnn_train_accuracy, cnn_validation_accuracy\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_trainer.plot_loss_history()\n",
    "resnet_trainer.plot_accuracy()\n",
    "\n",
    "resnet_train_accuracy = resnet_trainer.train_accuracy_history[-1]\n",
    "resnet_validation_accuracy = resnet_trainer.validation_accuracy_history[-1]\n",
    "print(\n",
    "    \"Train Accuracy = {}; Validation Accuracy = {}\".format(\n",
    "        resnet_train_accuracy, resnet_validation_accuracy\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_trainer.plot_loss_history()\n",
    "inception_trainer.plot_accuracy()\n",
    "\n",
    "inception_train_accuracy = inception_trainer.train_accuracy_history[-1]\n",
    "inception_validation_accuracy = inception_trainer.validation_accuracy_history[-1]\n",
    "print(\n",
    "    \"Train Accuracy = {}; Validation Accuracy = {}\".format(\n",
    "        inception_train_accuracy, inception_validation_accuracy\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_and_plot_confusion_matrix(model_cnn, cnn_trainer.val_dataset, use_cuda=torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_and_plot_confusion_matrix(model_resnet, resnet_trainer.val_dataset, use_cuda=torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_and_plot_confusion_matrix(model_inception, inception_trainer.val_dataset, use_cuda=torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze errors that occurred from confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = resnet_trainer # Change this\n",
    "model = model_resnet # Change this\n",
    "\n",
    "# Analyze confusion matrix and change these to observe results\n",
    "predicted_class_num = 0\n",
    "true_class_num = 0\n",
    "\n",
    "correct_class = [k for k, v in trainer.val_dataset.class_dict.items() if v == true_class_num][0]\n",
    "pred_class = key = [k for k, v in trainer.val_dataset.class_dict.items() if v == predicted_class_num][0]\n",
    "print(trainer.val_dataset.class_dict)\n",
    "\n",
    "paths = get_pred_images_for_target(model, trainer.val_dataset, predicted_class_num, true_class_num, torch.cuda.is_available())\n",
    "max_count = 10\n",
    "count = 0\n",
    "for path in paths:\n",
    "    img = Image.open(path).convert(mode='L')\n",
    "    if (count != max_count):\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.title(f'Image of {correct_class}, misclassified as {pred_class}')\n",
    "        plt.axis('off')  # Removes axis ticks\n",
    "        plt.show()\n",
    "        count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TumorTrace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
