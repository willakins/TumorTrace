{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison in The Domain of Brain Tumor Image Classification\n",
    "For our final project for Spring 2025, CS 4644 - Deep Learning, we analyze and compare the results from three unique models:\n",
    "1. 3D CNN - Turning 2D images into 3D datapoints to reconstruct a full brain image.\n",
    "2. ResNet18 - Applying transfer learning by taking a pretrained ResNet-18 model (trained on ImageNet) and adapting it to MRI scans through the fine-tuning of a final fully connected layer.\n",
    "3. Inception - Applying transfer learning in the same way as ResNet, but for another popular and successful model.\n",
    "\n",
    "The following code allows the reader to experiment with these 3 models and observe their results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0: Get necessary imports, set global variables, and setup dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "# Basic imports\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Model imports\n",
    "from src.models import (\n",
    "    CNN_3D,\n",
    "    MyResNet,\n",
    "    MyInception\n",
    ")\n",
    "# Helper imports\n",
    "from utils.utils import save_trained_model_weights\n",
    "from utils.dataset_utils import prepare_dataset\n",
    "from src import (\n",
    "    Trainer,\n",
    "    get_optimizer\n",
    ")\n",
    "from data.data_transforms import (\n",
    "    get_fundamental_transforms,\n",
    "    get_fundamental_normalization_transforms,\n",
    "    get_fundamental_augmentation_transforms,\n",
    "    get_all_transforms,\n",
    ")\n",
    "from utils.confusion_matrix import (\n",
    "    generate_confusion_data,\n",
    "    generate_confusion_matrix,\n",
    "    plot_confusion_matrix,\n",
    "    get_pred_images_for_target,\n",
    "    generate_and_plot_confusion_matrix,\n",
    "    generate_and_plot_accuracy_table,\n",
    ")\n",
    "\n",
    "# Global variables\n",
    "raw_data_path = \"../data/raw/\"\n",
    "data_path = \"../data/processed/\"\n",
    "model_path = \"../src/models\"\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 3\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Donwload the dataset, preprocess it, and compute statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Kaggle API token not found. Please follow these steps:\n1. Visit https://www.kaggle.com/account\n2. Click 'Create New API Token'\n3. type the following into your terminal if on MacOS/Linux:\nmkdir -p ~/.kaggle\nmv /path/to/downloaded/kaggle.json ~/.kaggle/\nchmod 600 ~/.kaggle/kaggle.json\n4. type the following into your terminal if on Windows:\nmkdir %USERPROFILE%\\.kaggle\nmove %USERPROFILE%\\Downloads\\kaggle.json %USERPROFILE%\\.kaggle\\ \n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m dataset_mean, dataset_std = \u001b[43mprepare_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mraw_data_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraw_data_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpickle_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_data_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbrain_tumor_mri/new_dataset/training_data.pickle\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprocessed_data_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:2\u001b[39m, in \u001b[36mprepare_dataset\u001b[39m\u001b[34m(raw_data_path, pickle_path, processed_data_path)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:4\u001b[39m, in \u001b[36mcheck_kaggle_auth\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: Kaggle API token not found. Please follow these steps:\n1. Visit https://www.kaggle.com/account\n2. Click 'Create New API Token'\n3. type the following into your terminal if on MacOS/Linux:\nmkdir -p ~/.kaggle\nmv /path/to/downloaded/kaggle.json ~/.kaggle/\nchmod 600 ~/.kaggle/kaggle.json\n4. type the following into your terminal if on Windows:\nmkdir %USERPROFILE%\\.kaggle\nmove %USERPROFILE%\\Downloads\\kaggle.json %USERPROFILE%\\.kaggle\\ \n"
     ]
    }
   ],
   "source": [
    "dataset_mean, dataset_std = prepare_dataset(\n",
    "    raw_data_path=raw_data_path,\n",
    "    pickle_path= os.path.join(raw_data_path, \"brain_tumor_mri/new_dataset/training_data.pickle\"),\n",
    "    processed_data_path=data_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyResNet(\n",
      "  (conv_layers): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  )\n",
      "  (fc_layers): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=512, out_features=3, bias=True)\n",
      "  )\n",
      "  (loss_criterion): CrossEntropyLoss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_resnet = MyResNet(num_classes=num_classes)\n",
    "print(model_resnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Test 3D Convolutional Nerual Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_size = (512,512) # TODO: Double check this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn = CNN_3D(num_classes=num_classes)\n",
    "\n",
    "cnn_optimizer_config = {\"optimizer_type\": \"adam\", \"lr\": 1e-3, \"weight_decay\": 1e-8} # Tune these\n",
    "cnn_optimizer = get_optimizer(model_cnn, cnn_optimizer_config)\n",
    "\n",
    "cnn_trainer = Trainer(\n",
    "    data_dir=data_path,\n",
    "    model=model_cnn,\n",
    "    optimizer=cnn_optimizer,\n",
    "    model_dir=os.path.join(model_path, \"CNN_3D\"),\n",
    "    train_data_transforms=get_all_transforms(inp_size, [dataset_mean], [dataset_std]),\n",
    "    val_data_transforms=get_fundamental_normalization_transforms(\n",
    "        inp_size, [dataset_mean], [dataset_std]\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    load_from_disk=False,\n",
    "    cuda=torch.cuda.is_available(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cnn_trainer.run_training_loop(num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_trainer.plot_loss_history()\n",
    "cnn_trainer.plot_accuracy()\n",
    "\n",
    "cnn_train_accuracy = cnn_trainer.train_accuracy_history[-1]\n",
    "cnn_validation_accuracy = cnn_trainer.validation_accuracy_history[-1]\n",
    "print(\n",
    "    \"Train Accuracy = {}; Validation Accuracy = {}\".format(\n",
    "        cnn_train_accuracy, cnn_validation_accuracy\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_trained_model_weights(model_cnn, out_dir=os.path.join(model_path, \"CNN_3D\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Test ResNet Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_size = (224,224) # Double check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet = MyResNet(num_classes=num_classes)\n",
    "\n",
    "resnet_optimizer_config = {\"optimizer_type\": \"adam\", \"lr\": 1e-3, \"weight_decay\": 1e-8} # Tune these\n",
    "resnet_optimizer = get_optimizer(model_resnet, resnet_optimizer_config)\n",
    "\n",
    "resnet_trainer = Trainer(\n",
    "    data_dir=data_path,\n",
    "    model=model_resnet,\n",
    "    optimizer=resnet_optimizer,\n",
    "    model_dir=os.path.join(model_path, \"ResNet\"),\n",
    "    train_data_transforms=get_all_transforms(inp_size, [dataset_mean], [dataset_std]),\n",
    "    val_data_transforms=get_fundamental_normalization_transforms(\n",
    "        inp_size, [dataset_mean], [dataset_std]\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    load_from_disk=False,\n",
    "    cuda=torch.cuda.is_available(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "resnet_trainer.run_training_loop(num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_trained_model_weights(model_resnet, out_dir=os.path.join(model_path, \"ResNet\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Test Inception Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_size = (299,299) # Double check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inception = MyInception(num_classes=num_classes)\n",
    "\n",
    "inception_optimizer_config = {\"optimizer_type\": \"adam\", \"lr\": 1e-3, \"weight_decay\": 1e-8} # Tune these\n",
    "inception_optimizer = get_optimizer(model_inception, inception_optimizer_config)\n",
    "\n",
    "inception_trainer = Trainer(\n",
    "    data_dir=data_path,\n",
    "    model=model_inception,\n",
    "    optimizer=inception_optimizer,\n",
    "    model_dir=os.path.join(model_path, \"Inception\"),\n",
    "    train_data_transforms=get_all_transforms(inp_size, [dataset_mean], [dataset_std]),\n",
    "    val_data_transforms=get_fundamental_normalization_transforms(\n",
    "        inp_size, [dataset_mean], [dataset_std]\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    load_from_disk=False,\n",
    "    cuda=torch.cuda.is_available(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "inception_trainer.run_training_loop(num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_trained_model_weights(model_inception, out_dir=os.path.join(model_path, \"Inception\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Analyze Graphs and Final Accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss & Accuracy Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_trainer.plot_loss_history()\n",
    "cnn_trainer.plot_accuracy()\n",
    "\n",
    "cnn_train_accuracy = cnn_trainer.train_accuracy_history[-1]\n",
    "cnn_validation_accuracy = cnn_trainer.validation_accuracy_history[-1]\n",
    "print(\n",
    "    \"Train Accuracy = {}; Validation Accuracy = {}\".format(\n",
    "        cnn_train_accuracy, cnn_validation_accuracy\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_trainer.plot_loss_history()\n",
    "resnet_trainer.plot_accuracy()\n",
    "\n",
    "resnet_train_accuracy = resnet_trainer.train_accuracy_history[-1]\n",
    "resnet_validation_accuracy = resnet_trainer.validation_accuracy_history[-1]\n",
    "print(\n",
    "    \"Train Accuracy = {}; Validation Accuracy = {}\".format(\n",
    "        resnet_train_accuracy, resnet_validation_accuracy\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_trainer.plot_loss_history()\n",
    "inception_trainer.plot_accuracy()\n",
    "\n",
    "inception_train_accuracy = inception_trainer.train_accuracy_history[-1]\n",
    "inception_validation_accuracy = inception_trainer.validation_accuracy_history[-1]\n",
    "print(\n",
    "    \"Train Accuracy = {}; Validation Accuracy = {}\".format(\n",
    "        inception_train_accuracy, inception_validation_accuracy\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_and_plot_confusion_matrix(model_cnn, cnn_trainer.val_dataset, use_cuda=torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_and_plot_confusion_matrix(model_resnet, resnet_trainer.val_dataset, use_cuda=torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_and_plot_confusion_matrix(model_inception, inception_trainer.val_dataset, use_cuda=torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze errors that occurred from confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = resnet_trainer # Change this\n",
    "model = model_resnet # Change this\n",
    "\n",
    "# Analyze confusion matrix and change these to observe results\n",
    "predicted_class_num = 0\n",
    "true_class_num = 0\n",
    "\n",
    "correct_class = [k for k, v in trainer.val_dataset.class_dict.items() if v == true_class_num][0]\n",
    "pred_class = key = [k for k, v in trainer.val_dataset.class_dict.items() if v == predicted_class_num][0]\n",
    "print(trainer.val_dataset.class_dict)\n",
    "\n",
    "paths = get_pred_images_for_target(model, trainer.val_dataset, predicted_class_num, true_class_num, torch.cuda.is_available())\n",
    "max_count = 10\n",
    "count = 0\n",
    "for path in paths:\n",
    "    img = Image.open(path).convert(mode='L')\n",
    "    if (count != max_count):\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.title(f'Image of {correct_class}, misclassified as {pred_class}')\n",
    "        plt.axis('off')  # Removes axis ticks\n",
    "        plt.show()\n",
    "        count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TumorTrace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
