{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison in The Domain of Brain Tumor Image Classification\n",
    "For our final project for Spring 2025, CS 4644 - Deep Learning, we analyze and compare the results from three unique models:\n",
    "1. 3D CNN - Turning 2D images into 3D datapoints to reconstruct a full brain image.\n",
    "2. ResNet18 - Applying transfer learning by taking a pretrained ResNet-18 model (trained on ImageNet) and adapting it to MRI scans through the fine-tuning of a final fully connected layer.\n",
    "3. Inception - Applying transfer learning in the same way as ResNet, but for another popular and successful model.\n",
    "\n",
    "The following code allows the reader to experiment with these 3 models and observe their results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0: Get necessary imports and set global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from data.Image_Loader import MRIDataset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import pickle\n",
    "\n",
    "# Model imports\n",
    "from src.models.CNN_3D.model import CNN_3D\n",
    "from src.models.ResNet.model import MyResNet\n",
    "from src.models.Inception.model import MyInception\n",
    "\n",
    "# Helper imports\n",
    "from src.runner import Trainer\n",
    "from src.optimizer import get_optimizer\n",
    "\n",
    "\n",
    "from data.data_transforms import (\n",
    "    get_fundamental_transforms,\n",
    "    get_fundamental_normalization_transforms,\n",
    "    get_fundamental_augmentation_transforms,\n",
    "    get_all_transforms,\n",
    ")\n",
    "from utils.utils import compute_mean_and_std\n",
    "from utils.confusion_matrix import (\n",
    "    generate_confusion_data,\n",
    "    generate_confusion_matrix,\n",
    "    plot_confusion_matrix,\n",
    "    get_pred_images_for_target,\n",
    "    generate_and_plot_confusion_matrix,\n",
    "    generate_and_plot_accuracy_table,\n",
    ")\n",
    "from utils.utils import save_trained_model_weights\n",
    "\n",
    "is_cuda = True\n",
    "is_cuda = (\n",
    "    is_cuda and torch.cuda.is_available()\n",
    ")  # will turn off cuda if the machine doesnt have a GPU\n",
    "\n",
    "data_path = \"./data/\"\n",
    "model_path = \"./src/models\"\n",
    "inp_size=(128,128) # determine trhough testing\n",
    "dataset_mean, dataset_std = compute_mean_and_std(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet = MyResNet()\n",
    "print(model_resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Data preloaded from pickle file\n",
    "data_path = os.path.abspath(os.path.join(\"..\", \"data\", \"archive\", \"brain_tumor_mri\", \"new_dataset\", \"training_data.pickle\"))\n",
    "with open(data_path, 'rb') as file:\n",
    "    loaded_data = pickle.load(file)\n",
    "\n",
    "# Unpacking the data into the images and their corresponding labels\n",
    "images, labels = zip(*loaded_data)\n",
    "dataset = MRIDataset(images, labels, transformations, model_type=None)\n",
    "\n",
    "# Splitting the dataset into training and testing\n",
    "training_size = int(.8 * len(dataset))\n",
    "testing_size = len(dataset) - training_size\n",
    "training_dataset, testing_dataset = random_split(dataset, [training_size, testing_size])\n",
    "\n",
    "# Two separate loaders for training and testing\n",
    "train_loader = DataLoader(training_dataset, batch_size=16, shuffle=True)\n",
    "testing_loader = DataLoader(testing_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Debug comment out later\n",
    "for sample_image, sample_label in train_loader:\n",
    "    print(f\"Image shape: {sample_image.shape}\")\n",
    "    print(f\"Label: {sample_label}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Test 3D Convolutional Nerual Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn = CNN_3D(num_classes=3)\n",
    "\n",
    "optimizer_config = {\"optimizer_type\": \"adam\", \"lr\": 1e-3, \"weight_decay\": 1e-8} # Tune these\n",
    "optimizer = get_optimizer(model_cnn, optimizer_config)\n",
    "\n",
    "trainer = Trainer(\n",
    "    data_dir=data_path,\n",
    "    model=model_cnn,\n",
    "    optimizer=optimizer,\n",
    "    model_dir=os.path.join(model_path, \"CNN_3D\"),\n",
    "    train_data_transforms=get_fundamental_transforms(inp_size),\n",
    "    val_data_transforms=get_fundamental_transforms(inp_size),\n",
    "    batch_size=32,\n",
    "    load_from_disk=False,\n",
    "    cuda=is_cuda,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trainer.run_training_loop(num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.plot_loss_history()\n",
    "trainer.plot_accuracy()\n",
    "\n",
    "train_accuracy = trainer.train_accuracy_history[-1]\n",
    "validation_accuracy = trainer.validation_accuracy_history[-1]\n",
    "print(\n",
    "    \"Train Accuracy = {}; Validation Accuracy = {}\".format(\n",
    "        train_accuracy, validation_accuracy\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Test ResNet Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet = MyResNet()\n",
    "\n",
    "optimizer_config = {\"optimizer_type\": \"adam\", \"lr\": 1e-3, \"weight_decay\": 1e-8}\n",
    "optimizer = get_optimizer(model_resnet, optimizer_config)\n",
    "\n",
    "trainer = Trainer(\n",
    "    data_dir=data_path,\n",
    "    model=model_resnet,\n",
    "    optimizer=optimizer,\n",
    "    model_dir=os.path.join(model_path, \"ResNet\"),\n",
    "    train_data_transforms=get_fundamental_transforms(inp_size),\n",
    "    val_data_transforms=get_fundamental_transforms(inp_size),\n",
    "    batch_size=32,\n",
    "    load_from_disk=False,\n",
    "    cuda=is_cuda,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trainer.run_training_loop(num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.plot_loss_history()\n",
    "trainer.plot_accuracy()\n",
    "\n",
    "train_accuracy = trainer.train_accuracy_history[-1]\n",
    "validation_accuracy = trainer.validation_accuracy_history[-1]\n",
    "print(\n",
    "    \"Train Accuracy = {}; Validation Accuracy = {}\".format(\n",
    "        train_accuracy, validation_accuracy\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Test Inception Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inception = MyInception()\n",
    "\n",
    "optimizer_config = {\"optimizer_type\": \"adam\", \"lr\": 1e-3, \"weight_decay\": 1e-8}\n",
    "optimizer = get_optimizer(model_inception, optimizer_config)\n",
    "\n",
    "trainer = Trainer(\n",
    "    data_dir=data_path,\n",
    "    model=model_inception,\n",
    "    optimizer=optimizer,\n",
    "    model_dir=os.path.join(model_path, \"Inception\"),\n",
    "    train_data_transforms=get_all_transforms(inp_size, [dataset_mean], [dataset_std]),\n",
    "    val_data_transforms=get_fundamental_normalization_transforms(\n",
    "        inp_size, [dataset_mean], [dataset_std]\n",
    "    ),\n",
    "    batch_size=32,\n",
    "    load_from_disk=False,\n",
    "    cuda=is_cuda,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trainer.run_training_loop(num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.plot_loss_history()\n",
    "trainer.plot_accuracy()\n",
    "\n",
    "train_accuracy = trainer.train_accuracy_history[-1]\n",
    "validation_accuracy = trainer.validation_accuracy_history[-1]\n",
    "print(\n",
    "    \"Train Accuracy = {}; Validation Accuracy = {}\".format(\n",
    "        train_accuracy, validation_accuracy\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TumorTrace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
