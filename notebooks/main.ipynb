{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "940f73af",
   "metadata": {},
   "source": [
    "# Model Comparison in The Domain of Brain Tumor Image Classification  \n",
    "For our final project for Spring 2025, CS 4644 - Deep Learning, we analyze and compare the results from three unique models:  \n",
    "1. 3D CNN - Turning 2D images into 3D datapoints to reconstruct a full brain image.  \n",
    "2. ResNet18 - Applying transfer learning by taking a pretrained ResNet-18 model (trained on ImageNet) and adapting it to MRI scans through the fine-tuning of a final fully connected layer.  \n",
    "3. Inception - Applying transfer learning in the same way as ResNet, but for another popular and successful model.  \n",
    "  \n",
    "The following code allows the reader to experiment with these 3 models and observe their results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf12d6d",
   "metadata": {},
   "source": [
    "# Step 0: Get necessary imports, set global variables, and setup dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a065692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "# Basic imports\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src import (\n",
    "    get_optimizer,\n",
    "    Trainer,\n",
    ")\n",
    "from src.models import (\n",
    "    CNN_3D,\n",
    "    MyResNet,\n",
    "    MyInception\n",
    ")\n",
    "from data.data_transforms import (\n",
    "    get_fundamental_transforms,\n",
    "    get_fundamental_normalization_transforms,\n",
    "    get_fundamental_augmentation_transforms,\n",
    "    get_all_transforms,\n",
    ")\n",
    "from utils.confusion_matrix import (\n",
    "    generate_confusion_data,\n",
    "    generate_confusion_matrix,\n",
    "    plot_confusion_matrix,\n",
    "    get_pred_images_for_target,\n",
    "    generate_and_plot_confusion_matrix,\n",
    "    generate_and_plot_accuracy_table,\n",
    ")\n",
    "from utils.utils import save_trained_model_weights\n",
    "from utils.dataset_utils import prepare_dataset\n",
    "\n",
    "#Folder paths\n",
    "raw_data_path = \"../data/raw/\"\n",
    "data_path = \"../data/processed/\"\n",
    "model_path = \"../src/models/\"\n",
    "results_path = \"../results/\"\n",
    "\n",
    "# Global Variables\n",
    "batch_size = 32\n",
    "num_classes = 3 # Output classes: Pituitary, Meningioma, and Glioma Tumor\n",
    "n_slices = 1 # TODO for 3D CNN: Change this if we find a pattern in the dataset for determining multiple images go to same patient\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4eef7f4",
   "metadata": {},
   "source": [
    "### Download the dataset, preprocess it, and compute statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22fba832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Kaggle API token found.\n",
      "[INFO] Raw data already exists. Skipping Kaggle download.\n",
      "[INFO] Processed data directory already exists. Skipping conversion.\n",
      "[INFO] Loading cached dataset mean and std...\n"
     ]
    }
   ],
   "source": [
    "dataset_mean, dataset_std = prepare_dataset(\n",
    "    raw_data_path=raw_data_path,\n",
    "    pickle_path= os.path.join(raw_data_path, \"brain_tumor_mri/new_dataset/training_data.pickle\"),\n",
    "    processed_data_path=data_path,\n",
    "    n_slices=n_slices, # TODO: figure out how many images in a row make up a 3d datapoint\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b35743",
   "metadata": {},
   "source": [
    "# Step 1: Test 3D Convolutional Nerual Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680328e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_size = (n_slices, 512, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b104aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn = CNN_3D(inp_size, num_classes=num_classes)\n",
    "\n",
    "cnn_optimizer_config = {\"optimizer_type\": \"adam\", \"lr\": 1e-3, \"weight_decay\": 1e-8} # Tune these\n",
    "cnn_optimizer = get_optimizer(model_cnn, cnn_optimizer_config)\n",
    "\n",
    "cnn_trainer = Trainer(\n",
    "    data_dir=data_path,\n",
    "    model=model_cnn,\n",
    "    optimizer=cnn_optimizer,\n",
    "    model_dir=os.path.join(model_path, \"CNN_3D\"),\n",
    "    train_data_transforms=get_all_transforms(tuple((inp_size[1], inp_size[2])), [dataset_mean], [dataset_std]),\n",
    "    val_data_transforms=get_fundamental_normalization_transforms(\n",
    "        tuple((inp_size[1], inp_size[2])), [dataset_mean], [dataset_std]\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    load_from_disk=False,\n",
    "    cuda=torch.cuda.is_available(),\n",
    "    n_slices=n_slices,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf81389",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cnn_trainer.run_training_loop(num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85add641",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_trainer.plot_loss_history()\n",
    "cnn_trainer.plot_accuracy()\n",
    "train_accuracy = cnn_trainer.train_accuracy_history[-1]\n",
    "validation_accuracy = cnn_trainer.validation_accuracy_history[-1]\n",
    "print(\n",
    "    \"Train Accuracy = {}; Validation Accuracy = {}\".format(\n",
    "        train_accuracy, validation_accuracy\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c138d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_trained_model_weights(model_cnn, out_dir=os.path.join(model_path, \"CNN_3D\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6ff5da",
   "metadata": {},
   "source": [
    "# Step 2: Test ResNet Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a14082",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_size = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad9bc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet = MyResNet(num_classes=num_classes)\n",
    "\n",
    "resnet_optimizer_config = {\"optimizer_type\": \"adam\", \"lr\": 1e-4, \"weight_decay\": 1e-8} # Tune these\n",
    "resnet_optimizer = get_optimizer(model_resnet, resnet_optimizer_config)\n",
    "\n",
    "resnet_trainer = Trainer(\n",
    "    data_dir=data_path,\n",
    "    model=model_resnet,\n",
    "    optimizer=resnet_optimizer,\n",
    "    model_dir=os.path.join(model_path, \"ResNet\"),\n",
    "    train_data_transforms=get_all_transforms(inp_size, [dataset_mean], [dataset_std]),\n",
    "    val_data_transforms=get_fundamental_normalization_transforms(\n",
    "        inp_size, [dataset_mean], [dataset_std]\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    load_from_disk=False,\n",
    "    cuda=torch.cuda.is_available(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0a5d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "resnet_trainer.run_training_loop(num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0911bf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_trainer.plot_loss_history()\n",
    "resnet_trainer.plot_accuracy()\n",
    "train_accuracy = resnet_trainer.train_accuracy_history[-1]\n",
    "validation_accuracy = resnet_trainer.validation_accuracy_history[-1]\n",
    "print(\n",
    "    \"Train Accuracy = {}; Validation Accuracy = {}\".format(\n",
    "        train_accuracy, validation_accuracy\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0a81ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_trained_model_weights(model_resnet, out_dir=os.path.join(model_path, \"ResNet\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16798afd",
   "metadata": {},
   "source": [
    "# Step 3: Test Inception Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bcbd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_size = (299,299)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc96352",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inception = MyInception(num_classes=num_classes)\n",
    "\n",
    "inception_optimizer_config = {\"optimizer_type\": \"adam\", \"lr\": 1e-4, \"weight_decay\": 1e-8} # Tune these\n",
    "inception_optimizer = get_optimizer(model_inception, inception_optimizer_config)\n",
    "\n",
    "inception_trainer = Trainer(\n",
    "    data_dir=data_path,\n",
    "    model=model_inception,\n",
    "    optimizer=inception_optimizer,\n",
    "    model_dir=os.path.join(model_path, \"Inception\"),\n",
    "    train_data_transforms=get_all_transforms(inp_size, [dataset_mean], [dataset_std]),\n",
    "    val_data_transforms=get_fundamental_normalization_transforms(\n",
    "        inp_size, [dataset_mean], [dataset_std]\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    load_from_disk=False,\n",
    "    cuda=torch.cuda.is_available(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760adf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "inception_trainer.run_training_loop(num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da7e304",
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_trainer.plot_loss_history()\n",
    "inception_trainer.plot_accuracy()\n",
    "train_accuracy = inception_trainer.train_accuracy_history[-1]\n",
    "validation_accuracy = inception_trainer.validation_accuracy_history[-1]\n",
    "print(\n",
    "    \"Train Accuracy = {}; Validation Accuracy = {}\".format(\n",
    "        train_accuracy, validation_accuracy\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bf80c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_trained_model_weights(model_inception, out_dir=os.path.join(model_path, \"Inception\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ae306c",
   "metadata": {},
   "source": [
    "# Step 4: Analyze Graphs and Final Accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d8a062",
   "metadata": {},
   "source": [
    "### Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353c4a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('3D CNN:', model_cnn.count_parameters())\n",
    "print('ResNet:', model_resnet.count_parameters())\n",
    "print('Inception:', model_inception.count_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145efb9e",
   "metadata": {},
   "source": [
    "### Classification Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae97db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_trainer.print_classification_report()\n",
    "resnet_trainer.print_classification_report()\n",
    "inception_trainer.print_classification_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9113f2",
   "metadata": {},
   "source": [
    "### Loss & Accuracy Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed0bd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_trainer.plot_loss_history()\n",
    "cnn_trainer.plot_accuracy()\n",
    "train_accuracy = cnn_trainer.train_accuracy_history[-1]\n",
    "validation_accuracy = cnn_trainer.validation_accuracy_history[-1]\n",
    "print(\n",
    "    \"Train Accuracy = {}; Validation Accuracy = {}\".format(\n",
    "        train_accuracy, validation_accuracy\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760d8d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_trainer.plot_loss_history()\n",
    "resnet_trainer.plot_accuracy()\n",
    "train_accuracy = resnet_trainer.train_accuracy_history[-1]\n",
    "validation_accuracy = resnet_trainer.validation_accuracy_history[-1]\n",
    "print(\n",
    "    \"Train Accuracy = {}; Validation Accuracy = {}\".format(\n",
    "        train_accuracy, validation_accuracy\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c7a81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_trainer.plot_loss_history()\n",
    "inception_trainer.plot_accuracy()\n",
    "train_accuracy = inception_trainer.train_accuracy_history[-1]\n",
    "validation_accuracy = inception_trainer.validation_accuracy_history[-1]\n",
    "print(\n",
    "    \"Train Accuracy = {}; Validation Accuracy = {}\".format(\n",
    "        train_accuracy, validation_accuracy\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2a4be4",
   "metadata": {},
   "source": [
    "### Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ea18b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_and_plot_confusion_matrix(model_cnn, cnn_trainer.val_dataset, path=results_path, use_cuda=torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4cd6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_and_plot_confusion_matrix(model_resnet, resnet_trainer.val_dataset, path=results_path, use_cuda=torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a981512",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_and_plot_confusion_matrix(model_inception, inception_trainer.val_dataset, path=results_path, use_cuda=torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf8397b",
   "metadata": {},
   "source": [
    "### Analyze errors that occurred from confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58eb3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = cnn_trainer # Change this\n",
    "model = model_cnn # Change this\n",
    "\n",
    "predicted_class_num = 1\n",
    "true_class_num = 2\n",
    "correct_class = [k for k, v in trainer.val_dataset.class_dict.items() if v == true_class_num][0]\n",
    "pred_class = key = [k for k, v in trainer.val_dataset.class_dict.items() if v == predicted_class_num][0]\n",
    "print(trainer.val_dataset.class_dict)\n",
    "\n",
    "paths = get_pred_images_for_target(model, trainer.val_dataset, predicted_class_num, true_class_num, torch.cuda.is_available())\n",
    "max_count = 1\n",
    "count = 0\n",
    "for path in paths:\n",
    "    img = Image.open(path).convert(mode='L')\n",
    "    if (count != max_count):\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.title(f'Image of {correct_class}, misclassified as {pred_class}')\n",
    "        plt.axis('off')  # Removes axis ticks\n",
    "        plt.savefig(os.path.join(results_path, f'{model.__class__.__name__}_misclassified.png')),\n",
    "        plt.show()\n",
    "        count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TumorTrace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
